{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EnsembleTechniques.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen3ravi/Machine_Learning/blob/main/EnsembleTechniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03lbhw76NWlL"
      },
      "source": [
        "## **Ensemble Technqiues**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jucpVMWMZrCW"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "TtSHXQ1wZr8W",
        "outputId": "281bde13-a4f9-4beb-e497-3142199d8e77"
      },
      "source": [
        "#importing important packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#reading the dataset\n",
        "df=pd.read_csv(\"train.csv\")\n",
        "#df\n",
        "\n",
        "# # #filling missing values\n",
        "# df['Gender'].fillna('Male', inplace=True)\n",
        "# df = df.dropna()\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-181131f8c0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#reading the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u_qacP7Z1KI"
      },
      "source": [
        "#split dataset into train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#del df['Loan_ID']\n",
        "#Both Label and One-hot encoding is performed\n",
        "dfT = pd.get_dummies(df) #encode the data\n",
        "dfT.columns\n",
        "dfT = dfT.drop(['Gender_Male','Married_No','Education_Graduate','Self_Employed_No'], axis = 1)\n",
        "dfT['Dependents'] = dfT['Dependents_0'] + (2 * dfT['Dependents_1']) + (3 * dfT['Dependents_2']) + (4 * dfT['Dependents_3+']) - 1\n",
        "dfT = dfT.drop(['Dependents_0','Dependents_1','Dependents_2','Dependents_3+'], axis = 1)\n",
        "dfT['Loan_Status'] = dfT['Loan_Status_Y']\n",
        "dfT = dfT.drop(['Loan_Status_Y','Loan_Status_N'], axis = 1)\n",
        "dfT\n",
        "\n",
        "#Split my data\n",
        "x_train, x_test, y_train, y_test = train_test_split(dfT[dfT.columns[:-1]].values, dfT['Loan_Status'].values, test_size=0.25, random_state=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac4vb2y_myQy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwFrtT-Z11y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd200ec-050e-4ea4-add6-b5625ea6ba26"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cb_8C3gaSW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbc81d3-c18c-4398-cb19-932eaa46cb0c"
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((369, 13), (123, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOwEsLjuO8L8"
      },
      "source": [
        "# Max Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGXJUGUCOViz"
      },
      "source": [
        "Alternatively, you can use “VotingClassifier” module in sklearn as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl6DolVOOVwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6e7e81-5621-4eb4-e7de-4c6c410b2778"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(max_depth = 2,random_state=1)\n",
        "model3 = KNeighborsClassifier(3)\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('knn',model3)], voting='hard') # it will stitich all the models together, voting = hard means max vting\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8130081300813008"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsdpgvE7ObnL"
      },
      "source": [
        "# Averaging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMvzYoGCqidv",
        "outputId": "e4d695f6-cfa0-4106-b69e-e8ebbc8ddf70"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(max_depth = 2,random_state=1)\n",
        "model3 = KNeighborsClassifier(3)\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('knn',model3)], voting='soft') # it will stitich all the models together, voting = soft means averaging coting\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8048780487804879"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3NYpy2IqyR5"
      },
      "source": [
        "# Weighted Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPEAPfanqymY",
        "outputId": "ad3431c8-1056-47ca-a188-1a9fe44f18eb"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(max_depth = 2,random_state=1)\n",
        "model3 = KNeighborsClassifier(3)\n",
        "model = VotingClassifier(weights = [0.2,0.2,0.6], estimators=[('lr', model1), ('dt', model2),('knn',model3)], voting='soft') # it will stitich all the models together, voting = soft means averaging coting\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7073170731707317"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN3oT9oqP-MM"
      },
      "source": [
        "# **Advanced Ensemble techniques**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c3aI7BnQB2T"
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMzD6i3GQouk"
      },
      "source": [
        "Predicting the predictions of the base model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgZ0DiBWQAvc"
      },
      "source": [
        "#Takes a single model, does cross-validation style splitting and gives the predictions of the model in the train dataset\n",
        "def Stacking(model,train,y,test,n_fold = 10):\n",
        "  folds=StratifiedKFold(n_splits=n_fold,random_state=1) # cross-validation : split the data into n_fold bins\n",
        "  test_pred=np.empty((0,1),float) #predictions var initialise\n",
        "  train_pred=np.empty((0,1),float) #predictions var initialise\n",
        "  for train_indices,val_indices in folds.split(train,y.values):\n",
        "    x_train,x_val=train.iloc[train_indices],train.iloc[val_indices] # chosse n_fold - 1 bins -> train test\n",
        "    y_train,y_val=y.iloc[train_indices],y.iloc[val_indices] # get test\n",
        "    model.fit(X=x_train,y=y_train) #fit the model \n",
        "    train_pred=np.append(train_pred,model.predict(x_val)) # training predictions \n",
        "  model.fit(train,y)\n",
        "  test_pred=np.append(test_pred,model.predict(x_test)) #test predictions \n",
        "  return test_pred.reshape(-1,1),train_pred #return the predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4qtSZOdQSxV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "65750f11-674b-4b5b-9d0c-7a738fa7ec4a"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
        "x_test = pd.DataFrame(x_test)\n",
        "x_train = pd.DataFrame(x_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "test_pred1, train_pred1=Stacking(model=model1,n_fold=10, train=x_train,test=x_test,y=y_train)\n",
        "\n",
        "train_pred1=pd.DataFrame(train_pred1)\n",
        "test_pred1=pd.DataFrame(test_pred1)\n",
        "train_pred1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>369 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "0    1.0\n",
              "1    1.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    0.0\n",
              "..   ...\n",
              "364  1.0\n",
              "365  1.0\n",
              "366  0.0\n",
              "367  1.0\n",
              "368  1.0\n",
              "\n",
              "[369 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV1kBEsXQUv5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "9fce0695-9a4b-4db9-bb0e-ce56f1368675"
      },
      "source": [
        "model2 = KNeighborsClassifier()\n",
        "\n",
        "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=x_train,test=x_test,y=y_train)\n",
        "\n",
        "train_pred2=pd.DataFrame(train_pred2)\n",
        "test_pred2=pd.DataFrame(test_pred2)\n",
        "train_pred2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>369 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "0    1.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    0.0\n",
              "..   ...\n",
              "364  0.0\n",
              "365  1.0\n",
              "366  0.0\n",
              "367  1.0\n",
              "368  1.0\n",
              "\n",
              "[369 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf9JVjq4QW0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bf6690-e9ba-439d-9f19-8bfa913679a4"
      },
      "source": [
        "df = pd.concat([train_pred1, train_pred2], axis=1) #dataframe containing both m1 and m2's predictions\n",
        "df_test = pd.concat([test_pred1, test_pred2], axis=1) \n",
        "\n",
        "model = LogisticRegression(random_state=1) #Stacked M3 model\n",
        "model.fit(df,y_train)\n",
        "\n",
        "#df_test\n",
        "model.score(df_test.values,y_test)\n",
        "# # y_test.values\n",
        "# #model.score(model.predict(df_test.values),y_test.values)\n",
        "# model.score(df_test.values, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6341463414634146"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdNDIpUjQa-x"
      },
      "source": [
        "Multiple levels in stacking?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JJM-WhyQdzj"
      },
      "source": [
        "# Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4BzLCSRRVCc"
      },
      "source": [
        "Blending is similar to bagging but rather than using a K fold cross validation, we use a single validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3h9X-JDd0vO"
      },
      "source": [
        "# **Bagging** (Bootstrap aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH9evpFKd15S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c3116c-79a8-4abc-cac2-6336a4ff9de9"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import tree\n",
        "# weakLearner = tree.DecisionTreeClassifier(max_depth = 1)\n",
        "# weakLearner.fit(x_train, y_train)\n",
        "# weakLearner.score(x_test,y_test)\n",
        "model = BaggingClassifier(tree.DecisionTreeClassifier(max_depth = 1, random_state=1), n_estimators=100)\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py:645: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8211382113821138"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n7miqMvhIA9"
      },
      "source": [
        "# **Random Forests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFbqvDeyhHgT",
        "outputId": "b40d48a2-5e0b-4c48-e3ec-468b0d4bf1c8"
      },
      "source": [
        "# Pandas is used for data manipulation\n",
        "import pandas as pd \n",
        "\n",
        "# Read in data as pandas dataframe and display first 5 rows\n",
        "original_features = pd.read_csv('temps.csv') #\n",
        "#original_features\n",
        "\n",
        "# Data cleaning\n",
        "# Data Encoding\n",
        "# Data Splitting\n",
        "# Data scaling\n",
        "# (if reqd) data transformation\n",
        "\n",
        "original_features.week = original_features.week.map({'Sun':1,'Mon':2,'Tues':3,'Wed':4,'Thurs':5,'Fri':6,'Sat':7})\n",
        "\n",
        "# Use numpy to convert to arrays\n",
        "import numpy as np\n",
        "\n",
        "# Labels are the values we want to predict\n",
        "original_labels = np.array(original_features['actual']) # target varaibles\n",
        "\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "original_features= original_features.drop('actual', axis = 1) #original features\n",
        "\n",
        "# Saving feature names for later use\n",
        "original_feature_list = list(original_features.columns) #orginal feature labels\n",
        "\n",
        "# Convert to numpy array\n",
        "original_features = np.array(original_features) \n",
        "\n",
        "# Using Skicit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "original_train_features, original_test_features, original_train_labels, original_test_labels = train_test_split(original_features, original_labels, test_size = 0.25, random_state = 42)\n",
        "\n",
        "# The baseline predictions are the historical averages\n",
        "baseline_preds = original_test_features[:, original_feature_list.index('average')]\n",
        "\n",
        "# Baseline errors, and display average baseline error\n",
        "baseline_errors = abs(baseline_preds - original_test_labels)\n",
        "print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'degrees.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average baseline error:  5.06 degrees.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qHTDK0Uy9Al",
        "outputId": "7ae79fa5-442c-4235-b706-df08e3986b93"
      },
      "source": [
        "original_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(348, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik6scJWniP-z",
        "outputId": "8203b858-7726-4257-e4c7-f1bb5ddbab37"
      },
      "source": [
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate model \n",
        "rf = RandomForestRegressor(n_estimators= 100, max_depth = 3, max_features='sqrt')\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(original_train_features, original_train_labels);\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(original_test_features)\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - original_test_labels)\n",
        "\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Average model error:', round(np.mean(errors), 2), 'degrees.')\n",
        "\n",
        "# Compare to baseline\n",
        "improvement_baseline = 100 * abs(np.mean(errors) - np.mean(baseline_errors)) / np.mean(baseline_errors)\n",
        "print('Improvement over baseline:', round(improvement_baseline, 2), '%.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average model error: 3.94 degrees.\n",
            "Improvement over baseline: 22.06 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STuw7_N80zYB",
        "outputId": "430983d2-5e40-4945-9a64-b9af50a4c3ee"
      },
      "source": [
        "original_train_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(261, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8PXQ0rZhsYd"
      },
      "source": [
        "rf_new = RandomForestRegressor(n_estimators = 100, criterion = 'mse', max_depth = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5nL5MSBimst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90e872d-558e-466e-c3f0-341587ec563f"
      },
      "source": [
        "original_feature_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['year', 'month', 'day', 'week', 'temp_2', 'temp_1', 'average', 'friend']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV4HSU4WiaUQ"
      },
      "source": [
        "# Interpret Model Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWAiLsut2MY3"
      },
      "source": [
        "from sklearn import tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6vkYkK3icNP"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import pydot\n",
        "\n",
        "# Pull out one tree from the forest\n",
        "tree = rf.estimators_[5]\n",
        "\n",
        "# Export the image to a dot file\n",
        "export_graphviz(tree, out_file = 'tree.dot', feature_names = original_feature_list, rounded = True, precision = 1)\n",
        "\n",
        "# Use dot file to create a graph\n",
        "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
        "\n",
        "# Write graph to a png file\n",
        "graph.write_png('tree.png');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60tIEyPXi5IT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22a521f-7cc4-40a4-cabf-bbf2e65e8623"
      },
      "source": [
        "print('The depth of this tree is:', tree.tree_.max_depth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The depth of this tree is: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3wF-cTi7qt"
      },
      "source": [
        "# Limit depth of tree to 2 levels\n",
        "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
        "rf_small.fit(original_train_features, original_train_labels)\n",
        "\n",
        "# Extract the small tree\n",
        "tree_small = rf_small.estimators_[5]\n",
        "\n",
        "# Save the tree as a png image\n",
        "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = original_feature_list, rounded = True, precision = 1)\n",
        "\n",
        "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
        "\n",
        "graph.write_png('small_tree.png');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhUtbce0jnO3"
      },
      "source": [
        "# Variable Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdbdpAXkjqHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364c59b4-c59e-416d-b47e-7f9d892f9697"
      },
      "source": [
        "\n",
        "# Get numerical feature importances\n",
        "importances = list(rf.feature_importances_)\n",
        "\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(original_feature_list, importances)]\n",
        "\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "# Print out the feature and importances \n",
        "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable: temp_1               Importance: 0.35\n",
            "Variable: average              Importance: 0.25\n",
            "Variable: temp_2               Importance: 0.24\n",
            "Variable: month                Importance: 0.09\n",
            "Variable: friend               Importance: 0.06\n",
            "Variable: day                  Importance: 0.01\n",
            "Variable: week                 Importance: 0.01\n",
            "Variable: year                 Importance: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRoxVJqDj6gC"
      },
      "source": [
        "# Model with the 2 most important feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DbrjWloj-yW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac4fb0b-c392-47a7-ecf2-bcec4006dabb"
      },
      "source": [
        "\n",
        "# New random forest with only the two most important variables\n",
        "rf_most_important = RandomForestRegressor(n_estimators= 100, max_depth = 2, max_features='auto')\n",
        "\n",
        "# Extract the two most important features\n",
        "important_indices = [original_feature_list.index('temp_1'), original_feature_list.index('average')]\n",
        "train_important = original_train_features[:, important_indices]\n",
        "test_important = original_test_features[:, important_indices]\n",
        "\n",
        "# Train the random forest\n",
        "rf_most_important.fit(train_important, original_train_labels)\n",
        "\n",
        "# Make predictions and determine the error\n",
        "predictions = rf_most_important.predict(test_important)\n",
        "\n",
        "errors = abs(predictions - original_test_labels)\n",
        "\n",
        "# Display the performance metrics\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
        "\n",
        "mape = np.mean(100 * (errors / original_test_labels))\n",
        "accuracy = 100 - mape\n",
        "\n",
        "print('Accuracy:', round(accuracy, 2), '%.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 3.92 degrees.\n",
            "Accuracy: 93.81 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSt7rIY8k3DJ"
      },
      "source": [
        "# **Gradient Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njlq3MibzGxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1116cf-3f0e-4a21-b6d0-e9c8e73af5ee"
      },
      "source": [
        "x_train = original_train_features\n",
        "y_train = original_train_labels\n",
        "x_test = original_test_features\n",
        "y_test = original_test_labels\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.016e+03, 9.000e+00, 1.900e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [2.016e+03, 4.000e+00, 1.400e+01, ..., 1.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [2.016e+03, 7.000e+00, 3.000e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       ...,\n",
              "       [2.016e+03, 4.000e+00, 1.900e+01, ..., 0.000e+00, 1.000e+00,\n",
              "        0.000e+00],\n",
              "       [2.016e+03, 1.000e+01, 1.400e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [2.016e+03, 4.000e+00, 1.500e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCPCO2F5ywry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221e965b-f0a8-4826-ac53-54882956cca3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(max_depth = 3, n_estimators = 100)\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.828767914938442"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xadPnWPuk5aT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5aed57-0d0d-4de7-d1be-da725222c6c8"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "for lr in [0.01,0.05,0.1,0.3,0.5,0.8,1]:\n",
        "  model= GradientBoostingRegressor(learning_rate=lr)\n",
        "  model.fit(x_train, y_train)\n",
        "  print(\"Learning rate : \", lr, \" Train score : \", model.score(x_train,y_train), \" Test score : \", model.score(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate :  0.01  Train score :  0.748448119171244  Test score :  0.6987030889939783\n",
            "Learning rate :  0.05  Train score :  0.9367569917605779  Test score :  0.8115207441916898\n",
            "Learning rate :  0.1  Train score :  0.9633872610566124  Test score :  0.8072216385403231\n",
            "Learning rate :  0.3  Train score :  0.9940863231870001  Test score :  0.780475702844597\n",
            "Learning rate :  0.5  Train score :  0.9990143690441512  Test score :  0.771937412771505\n",
            "Learning rate :  0.8  Train score :  0.9999125230875202  Test score :  0.7393969546045693\n",
            "Learning rate :  1  Train score :  0.9999741596184119  Test score :  0.6685132910693539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69TgRljQwpwj"
      },
      "source": [
        "# XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvg6zsMFii6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980ad805-c50f-458a-ee04-baa7b33fe87e"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "for lr in [0.01,0.05,0.1,0.11,0.12,0.13,0.14,0.15,0.2,0.5,0.7,1]:\n",
        "  model = xgb.XGBRegressor(learning_rate = lr, n_estimators=100)\n",
        "  model.fit(x_train,y_train)\n",
        "  model.score(x_test, y_test)\n",
        "  print(\"Learning rate : \", lr, \" Train score : \", model.score(x_train,y_train), \" Test score : \", np.mean(cross_val_score(model, x_train, y_train, cv=10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.01  Train score :  -3.0966307094653214  Test score :  -3.5706615026836572\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.05  Train score :  0.9216373955168508  Test score :  0.8052433145055206\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.1  Train score :  0.9517037540650602  Test score :  0.7988617424624916\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.11  Train score :  0.9561983172862579  Test score :  0.7953905014619669\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.12  Train score :  0.9593151446418337  Test score :  0.7908176942769146\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.13  Train score :  0.9609453637003088  Test score :  0.786918154141506\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.14  Train score :  0.9641559195887202  Test score :  0.7969627269870386\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.15  Train score :  0.968615922938024  Test score :  0.7843422725836197\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.2  Train score :  0.9787143846365524  Test score :  0.7742699241675972\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.5  Train score :  0.9983213618469642  Test score :  0.754435012597511\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  0.7  Train score :  0.9993996508309024  Test score :  0.701465273881636\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[05:19:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Learning rate :  1  Train score :  0.9999002102492711  Test score :  0.6677939239288918\n"
          ]
        }
      ]
    }
  ]
}